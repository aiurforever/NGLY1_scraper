name: Run NGLY1 Web Scraper

on:
  schedule:
    - cron: '0 0 * * *'  # Runs daily
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install beautifulsoup4 pandas requests

      - name: Run web scraper
        run: |
          python3 scraper.py --cli > scraper.log 2>&1 || (cat scraper.log && exit 1)

      - name: Check if CSV exists
        run: |
          if [ ! -f "news_mentions.csv" ]; then
            echo "‚ùå ERROR: news_mentions.csv not found!"
            exit 1
          fi

      - name: Upload results
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: ngly1_mentions
          path: news_mentions.csv

      - name: Upload Debug Logs
        uses: actions/upload-artifact@v4
        with:
          name: debug-logs
          path: scraper.log
